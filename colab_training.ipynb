{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1-rZoaQtC5REcXvbg11zWn_cIWy8KBk1F","authorship_tag":"ABX9TyOYVrAXWRvoCNBj3KuZKA9/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RJNCR0a8eRC","executionInfo":{"status":"ok","timestamp":1705064763180,"user_tz":-60,"elapsed":783,"user":{"displayName":"AdimadLp","userId":"05864867446893575020"}},"outputId":"7132b9a9-1499-4333-a9b2-678d52255d5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'arc_benchmark_tutorial'...\n","remote: Enumerating objects: 985, done.\u001b[K\n","remote: Counting objects: 100% (985/985), done.\u001b[K\n","remote: Compressing objects: 100% (461/461), done.\u001b[K\n","remote: Total 985 (delta 531), reused 978 (delta 524), pack-reused 0\u001b[K\n","Receiving objects: 100% (985/985), 515.26 KiB | 2.03 MiB/s, done.\n","Resolving deltas: 100% (531/531), done.\n"]}],"source":["!git clone https://github.com/AdimadLp/arc_benchmark_tutorial.git"]},{"cell_type":"code","source":["cd arc_benchmark_tutorial"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFdMfBMvBSXY","executionInfo":{"status":"ok","timestamp":1705064763181,"user_tz":-60,"elapsed":5,"user":{"displayName":"AdimadLp","userId":"05864867446893575020"}},"outputId":"f22058ef-0d58-427a-e1d5-0e7e7c7dfd00"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/arc_benchmark_tutorial\n"]}]},{"cell_type":"code","source":["import train_gpt2"],"metadata":{"id":"cs1w_uZyCt6Q","executionInfo":{"status":"ok","timestamp":1705064769766,"user_tz":-60,"elapsed":6588,"user":{"displayName":"AdimadLp","userId":"05864867446893575020"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# continue traing\n","model_path = \"gpt2_medium_2e-05_10\"\n","%cp -av \"/content/drive/MyDrive/Uni/5. Semester/Large Language Models/arc_benchmark_tutorial/gpt2_medium_2e-05_10\" \"gpt2_medium_2e-05_10\"\n","learning_rate = float(model_path.split('_')[-2])\n","epoch = int(model_path.split('_')[-1])\n","batch_size = 1"],"metadata":{"id":"uEGjsKrFBYeJ","executionInfo":{"status":"ok","timestamp":1705064999556,"user_tz":-60,"elapsed":5984,"user":{"displayName":"AdimadLp","userId":"05864867446893575020"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1dd14790-12ab-4576-fa6b-0c2337ecc2f6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["'/content/drive/MyDrive/Uni/5. Semester/Large Language Models/arc_benchmark_tutorial/gpt2_medium_2e-05_10' -> 'gpt2_medium_2e-05_10'\n","'/content/drive/MyDrive/Uni/5. Semester/Large Language Models/arc_benchmark_tutorial/gpt2_medium_2e-05_10/config.json' -> 'gpt2_medium_2e-05_10/config.json'\n","'/content/drive/MyDrive/Uni/5. Semester/Large Language Models/arc_benchmark_tutorial/gpt2_medium_2e-05_10/generation_config.json' -> 'gpt2_medium_2e-05_10/generation_config.json'\n","'/content/drive/MyDrive/Uni/5. Semester/Large Language Models/arc_benchmark_tutorial/gpt2_medium_2e-05_10/model.safetensors' -> 'gpt2_medium_2e-05_10/model.safetensors'\n","'/content/drive/MyDrive/Uni/5. Semester/Large Language Models/arc_benchmark_tutorial/gpt2_medium_2e-05_10/tokenizer_config.json' -> 'gpt2_medium_2e-05_10/tokenizer_config.json'\n","'/content/drive/MyDrive/Uni/5. Semester/Large Language Models/arc_benchmark_tutorial/gpt2_medium_2e-05_10/vocab.json' -> 'gpt2_medium_2e-05_10/vocab.json'\n","'/content/drive/MyDrive/Uni/5. Semester/Large Language Models/arc_benchmark_tutorial/gpt2_medium_2e-05_10/special_tokens_map.json' -> 'gpt2_medium_2e-05_10/special_tokens_map.json'\n","'/content/drive/MyDrive/Uni/5. Semester/Large Language Models/arc_benchmark_tutorial/gpt2_medium_2e-05_10/merges.txt' -> 'gpt2_medium_2e-05_10/merges.txt'\n"]}]},{"cell_type":"code","source":["# start training\n","# model_path = 'gpt2'\n","# learning_rate = 2e-5\n","# epoch = 0\n","# batch_size = 1\n","# train(model_path, learning_rate, batch_size, epoch)"],"metadata":{"id":"38ccIcyhyAf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_gpt2.train(model_path, learning_rate, batch_size, epoch, model_name=str(model_path.split('_')[:-3]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCPOB3OiCb7T","outputId":"7e6a8f63-12ac-4968-a887-1261993804f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model_path: gpt2_medium_2e-05_10\n","learning_rate: 2e-05\n","batch_size: 1\n","epoch: 10\n","Tokenizer loaded\n","Model loaded\n","Taining data loaded\n","Evaluation data loaded\n","Start training...\n","Step 10, Loss: 0.135317862033844\n","Step 20, Loss: 0.24558213353157043\n","Step 30, Loss: 0.16677294671535492\n","Step 40, Loss: 0.1645706743001938\n","Step 50, Loss: 0.12877854704856873\n","Step 60, Loss: 0.09574391692876816\n","Step 70, Loss: 0.09197213500738144\n","Step 80, Loss: 0.2427433431148529\n","Step 90, Loss: 0.11047998815774918\n","Step 100, Loss: 0.19983859360218048\n","Step 110, Loss: 0.17327319085597992\n","Step 120, Loss: 0.15185444056987762\n","Step 130, Loss: 0.06918319314718246\n","Step 140, Loss: 0.16811811923980713\n","Step 150, Loss: 0.09690597653388977\n","Step 160, Loss: 0.3978383243083954\n","Step 170, Loss: 0.20868061482906342\n","Step 180, Loss: 0.1542125642299652\n","Step 190, Loss: 0.1398300975561142\n","Step 200, Loss: 0.09527179598808289\n","Step 210, Loss: 0.2395831197500229\n","Step 220, Loss: 0.09376039355993271\n","Step 230, Loss: 0.12126759439706802\n","Step 240, Loss: 0.15578731894493103\n","Step 250, Loss: 0.15691682696342468\n","Step 260, Loss: 0.147830531001091\n","Step 270, Loss: 0.07653820514678955\n","Step 280, Loss: 0.15288284420967102\n","Step 290, Loss: 0.18535010516643524\n","Step 300, Loss: 0.11874017864465714\n","Step 310, Loss: 0.32321813702583313\n","Step 320, Loss: 0.09245653450489044\n","Step 330, Loss: 0.2860189974308014\n","Step 340, Loss: 0.10747789591550827\n","Step 350, Loss: 0.1734994649887085\n","Step 360, Loss: 0.3869667053222656\n","Step 370, Loss: 0.0885210782289505\n","Step 380, Loss: 0.20322492718696594\n","Step 390, Loss: 0.16033433377742767\n","Step 400, Loss: 0.1486184000968933\n","Epoch 11 completed with loss 0.1486184000968933\n","Visualizing example 1 of model ['gpt2']_2e-05_11\n","Generated text is not JSON compatible: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[7, 7, 8, 8, 8, 5, 5, 8], [5, 5, 8, 5, 8, 5, 5, 8], [7, 7, 8, 8, 8, 7, 7, 8], [8, 5, 7, 8, 8, 8, 5, 7], [5, 5, 8, 5, 8, 5, 5, 8], [8, 5, 7, 8, 8, 7, 7, 8], [7, 7, 8, 8, 8, 5, 5, 8]]\n","Input: [[1, 4, 8, 1], [1, 4, 4, 1], [8, 2, 8, 8]] Output: [[1, 4, 4, 1, 1, 4, 4, 1, 4], [1, 1, 4, 1, 1, 1, 1, 4, 4], [1, 4, 4, 1, 1, 1, 1, 1, 4], [1, 4, 4, 1, 1, 1, 1, 1, 4], [8, 2, 8, 8, 8, 2, 8, 8, 2], [2, 8, 8, 8, 8, 2, 8, 8, 2], [8, 2, 8, 8, 8, 2, 8, 8, 2], [4, 4, 8, 1, 1, 4, 4, 1, 4], [4, 4, 4, 1, 1, 1, 1, 4, 4], [1, 4, 4, 1, 1, 1, 4, 4, 1]]\n","Input: [[2, 5, 9, 9], [5, 5, 5, 5], [6, 4, 6, 4], [4, 5, 5, 3]] Output: [[2, 5, 9, 9, 2, 5, 9, 9, 2], [5, 5, 5, 5, 5, 5, 5, 5, 5], [6, 4, 6, 4, 6, 4, 6, 4, 6], [4, 5, 5, 3, 5, 5, 5, 5, 5], [6, 4, 6, 4, 6, 4, 6, 4, 6], [5, 5, 5, 5, 5, 5, 5, 5, 5], [6, 4, 6, 4, 6, 4, 6, 4, 6], [2, 5, 9, 9, 2, 5, 9, 9, 2], [5, 5, 5, 5, 5, 5, 5, 5, 5], [6, 4, 6, 4, 6, 4, 6, 4, 6], [4, 5, 5, 3, 5, 5, 5, 5, 5],\n","Visualizing example 3 of model ['gpt2']_2e-05_11\n","Visualizing example 4 of model ['gpt2']_2e-05_11\n","Visualizing example 5 of model ['gpt2']_2e-05_11\n","Step 10, Loss: 0.20253190398216248\n","Step 20, Loss: 0.3148083984851837\n","Step 30, Loss: 0.136085644364357\n","Step 40, Loss: 0.1023392304778099\n","Step 50, Loss: 0.1018049567937851\n","Step 60, Loss: 0.05609472468495369\n","Step 70, Loss: 0.2893510162830353\n","Step 80, Loss: 0.1416344940662384\n","Step 90, Loss: 0.17138147354125977\n","Step 100, Loss: 0.07256554812192917\n","Step 110, Loss: 0.08752176910638809\n","Step 120, Loss: 0.344903826713562\n","Step 130, Loss: 0.0758332908153534\n","Step 140, Loss: 0.0909644290804863\n","Step 150, Loss: 0.38186752796173096\n","Step 160, Loss: 0.06259977072477341\n","Step 170, Loss: 0.17831741273403168\n","Step 180, Loss: 0.07282552123069763\n","Step 190, Loss: 0.11692195385694504\n","Step 200, Loss: 0.10804884880781174\n","Step 210, Loss: 0.20377804338932037\n","Step 220, Loss: 0.1456548273563385\n","Step 230, Loss: 0.1980527937412262\n","Step 240, Loss: 0.10731612145900726\n","Step 250, Loss: 0.12465989589691162\n","Step 260, Loss: 0.13134361803531647\n","Step 270, Loss: 0.14139634370803833\n","Step 280, Loss: 0.15379148721694946\n","Step 290, Loss: 0.1348992884159088\n","Step 300, Loss: 0.19910433888435364\n","Step 310, Loss: 0.17690886557102203\n","Step 320, Loss: 0.189794659614563\n","Step 330, Loss: 0.25265049934387207\n","Step 340, Loss: 0.2323729544878006\n","Step 350, Loss: 0.10504477471113205\n","Step 360, Loss: 0.19031260907649994\n","Step 370, Loss: 0.07241914421319962\n","Step 380, Loss: 0.1124369353055954\n","Step 390, Loss: 0.05318261682987213\n","Step 400, Loss: 0.08979097008705139\n","Epoch 12 completed with loss 0.08979097008705139\n","Visualizing example 1 of model ['gpt2']_2e-05_12\n","Visualizing example 2 of model ['gpt2']_2e-05_12\n","Visualizing example 3 of model ['gpt2']_2e-05_12\n","Visualizing example 4 of model ['gpt2']_2e-05_12\n","Visualizing example 5 of model ['gpt2']_2e-05_12\n","Step 10, Loss: 0.2176293581724167\n","Step 20, Loss: 0.15121540427207947\n"]}]}]}