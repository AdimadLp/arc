{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1-rZoaQtC5REcXvbg11zWn_cIWy8KBk1F","authorship_tag":"ABX9TyOZzUkbB/JCcfbgFVS3pDL3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a1038ea37e834c628fcf38fec71c133a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52fa5078b420481da4113b0d0e0edc21","IPY_MODEL_e1f18eb7c0b74f7289f988b33015460a","IPY_MODEL_663b72ad00bc490cbcd6bc294f43904d"],"layout":"IPY_MODEL_8f320dc41de24b05a0e15d4fcc9e04c6"}},"52fa5078b420481da4113b0d0e0edc21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fd668c5710444c68092ade8202e1f36","placeholder":"​","style":"IPY_MODEL_e9ab00d2fa38433ca1e9ad58a6179b32","value":"vocab.json: 100%"}},"e1f18eb7c0b74f7289f988b33015460a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b64bd80c592492e897977d840c477a4","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82f2ee38d67d43bc9af915346a3c2f9a","value":1042301}},"663b72ad00bc490cbcd6bc294f43904d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b4142b4d2f0429fa5d7bb74dd71769a","placeholder":"​","style":"IPY_MODEL_ba2b2b9f8de64a4886a8d2cdb5059afb","value":" 1.04M/1.04M [00:00&lt;00:00, 11.4MB/s]"}},"8f320dc41de24b05a0e15d4fcc9e04c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fd668c5710444c68092ade8202e1f36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9ab00d2fa38433ca1e9ad58a6179b32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b64bd80c592492e897977d840c477a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82f2ee38d67d43bc9af915346a3c2f9a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b4142b4d2f0429fa5d7bb74dd71769a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba2b2b9f8de64a4886a8d2cdb5059afb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24d3924ef1e940d183bf30d981834cfa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5ac3c21cbde40a488e2cc4f945ac8e4","IPY_MODEL_77dd71eebc8a4f48acdfa3d9ec9c1bc1","IPY_MODEL_7c15e8d8253b4f2eb200c388b67aa86f"],"layout":"IPY_MODEL_6f9cc3dffe60409ab75e0c327dfed300"}},"b5ac3c21cbde40a488e2cc4f945ac8e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d2a8c50e98d43d3ab59c521dc7616ec","placeholder":"​","style":"IPY_MODEL_846a66e6a2614600b66dbb665fdfe937","value":"merges.txt: 100%"}},"77dd71eebc8a4f48acdfa3d9ec9c1bc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_213e57b93c5741379f4f0d3e5b3f77e8","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61642a4871144c6ea912c776669bcc89","value":456318}},"7c15e8d8253b4f2eb200c388b67aa86f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fe107b890f64716952deca216f5fd4f","placeholder":"​","style":"IPY_MODEL_e22a63d00f784478b6234786e470b796","value":" 456k/456k [00:00&lt;00:00, 21.2MB/s]"}},"6f9cc3dffe60409ab75e0c327dfed300":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d2a8c50e98d43d3ab59c521dc7616ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"846a66e6a2614600b66dbb665fdfe937":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"213e57b93c5741379f4f0d3e5b3f77e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61642a4871144c6ea912c776669bcc89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7fe107b890f64716952deca216f5fd4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e22a63d00f784478b6234786e470b796":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4502ac73bc84410eb2af0da63e1a81dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6fc39753c1f47d992214ad0e605b858","IPY_MODEL_a9ec11f58f8a45cdaadd8f6abfe2d0e2","IPY_MODEL_d91977ef1d17432d9085647a95f1e6e1"],"layout":"IPY_MODEL_5a168f68a1d14f5c887eeae5b89b9b0b"}},"a6fc39753c1f47d992214ad0e605b858":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b798b2abdf0841418c4ad46c83683c76","placeholder":"​","style":"IPY_MODEL_405d150e9c074f0d965211742cffbacf","value":"tokenizer.json: 100%"}},"a9ec11f58f8a45cdaadd8f6abfe2d0e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b00762c111d74d9eb88e009387eb7bb1","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5056bc9b0d3473cb9c6e513db5691ad","value":1355256}},"d91977ef1d17432d9085647a95f1e6e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80ba65468725465f92cf6b09ffd057a8","placeholder":"​","style":"IPY_MODEL_d915a92a723f40ac89eef3ef0cb68aa9","value":" 1.36M/1.36M [00:00&lt;00:00, 33.4MB/s]"}},"5a168f68a1d14f5c887eeae5b89b9b0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b798b2abdf0841418c4ad46c83683c76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"405d150e9c074f0d965211742cffbacf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b00762c111d74d9eb88e009387eb7bb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5056bc9b0d3473cb9c6e513db5691ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80ba65468725465f92cf6b09ffd057a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d915a92a723f40ac89eef3ef0cb68aa9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d989a4a34434f1bb76245d58d45a7fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e6530d60a524f27bcce310167e80930","IPY_MODEL_39b6cf4e1b934ca9af94d54de24ea20f","IPY_MODEL_b834d97adf0f42edbf089d503cd1e023"],"layout":"IPY_MODEL_f98aab0ea0b6485a93e1779360507f19"}},"0e6530d60a524f27bcce310167e80930":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a401b61f37c49f1863c2a7ab62bced8","placeholder":"​","style":"IPY_MODEL_4bac9f92088748c4b91b5ada96b84a58","value":"config.json: 100%"}},"39b6cf4e1b934ca9af94d54de24ea20f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a89dd5bc876d419faf8f0984e1ab7dbe","max":718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e5eef070d1748b094e9eb36b3a60cd0","value":718}},"b834d97adf0f42edbf089d503cd1e023":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3efd8d5b1e32451ea104341bf4803b0b","placeholder":"​","style":"IPY_MODEL_74c3dc0934e04a21901b0dcfe6c0a9e4","value":" 718/718 [00:00&lt;00:00, 35.4kB/s]"}},"f98aab0ea0b6485a93e1779360507f19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a401b61f37c49f1863c2a7ab62bced8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bac9f92088748c4b91b5ada96b84a58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a89dd5bc876d419faf8f0984e1ab7dbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e5eef070d1748b094e9eb36b3a60cd0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3efd8d5b1e32451ea104341bf4803b0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74c3dc0934e04a21901b0dcfe6c0a9e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53f05ef1220c45abb62c51fa64a6c8f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_add9957add60434b8b4d01b1dde49af2","IPY_MODEL_b5e701abc08f4cbd8c57b64ee0edf43c","IPY_MODEL_45ae0f57357f48208427a28487561278"],"layout":"IPY_MODEL_df9ce5663d0845eeb6880a21d5612d3b"}},"add9957add60434b8b4d01b1dde49af2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cecf73529764df0af8bb7c68684d114","placeholder":"​","style":"IPY_MODEL_9939d27e494047eb9621f0f647f00f68","value":"model.safetensors: 100%"}},"b5e701abc08f4cbd8c57b64ee0edf43c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c768f7a1249d43009a58ec24a55573e7","max":1519984962,"min":0,"orientation":"horizontal","style":"IPY_MODEL_061e5af6f56a40b7aebad0a8fa206ca4","value":1519984962}},"45ae0f57357f48208427a28487561278":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c6b4c3945f24ee9970a335bd0c87d57","placeholder":"​","style":"IPY_MODEL_262748c1476f43658ac941e6898ac4d9","value":" 1.52G/1.52G [00:10&lt;00:00, 187MB/s]"}},"df9ce5663d0845eeb6880a21d5612d3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cecf73529764df0af8bb7c68684d114":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9939d27e494047eb9621f0f647f00f68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c768f7a1249d43009a58ec24a55573e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"061e5af6f56a40b7aebad0a8fa206ca4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c6b4c3945f24ee9970a335bd0c87d57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"262748c1476f43658ac941e6898ac4d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05c721290c8e4f878ee7e0335bebeacf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3477cf4b96f945fe94d4972710f7bee7","IPY_MODEL_10e9e8cf54814c348ee2500da0d522d7","IPY_MODEL_15c0ca2daf974d6c8f4932e496e1956a"],"layout":"IPY_MODEL_2ca831c8eb5f4ff48e48934873965d36"}},"3477cf4b96f945fe94d4972710f7bee7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a9ffe84a1db48ca8decd4b482862df7","placeholder":"​","style":"IPY_MODEL_ee099bf379de40249c085834baad3356","value":"generation_config.json: 100%"}},"10e9e8cf54814c348ee2500da0d522d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_544ef8f435b14f17a57ed7f24913cc90","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31b120cad708469183060cc38bb7eef0","value":124}},"15c0ca2daf974d6c8f4932e496e1956a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c62325b2ae3e493c85111706ec2173f4","placeholder":"​","style":"IPY_MODEL_942001eab83d48ebb921cd88f9e1b81d","value":" 124/124 [00:00&lt;00:00, 6.80kB/s]"}},"2ca831c8eb5f4ff48e48934873965d36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a9ffe84a1db48ca8decd4b482862df7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee099bf379de40249c085834baad3356":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"544ef8f435b14f17a57ed7f24913cc90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31b120cad708469183060cc38bb7eef0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c62325b2ae3e493c85111706ec2173f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"942001eab83d48ebb921cd88f9e1b81d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RJNCR0a8eRC","executionInfo":{"status":"ok","timestamp":1705061395770,"user_tz":-60,"elapsed":1205,"user":{"displayName":"AdimadLp","userId":"05864867446893575020"}},"outputId":"9bf95bdd-856f-4abc-be74-5daeb611ca93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'arc_benchmark_tutorial'...\n","remote: Enumerating objects: 973, done.\u001b[K\n","remote: Counting objects: 100% (973/973), done.\u001b[K\n","remote: Compressing objects: 100% (453/453), done.\u001b[K\n","remote: Total 973 (delta 525), reused 968 (delta 520), pack-reused 0\u001b[K\n","Receiving objects: 100% (973/973), 480.09 KiB | 8.28 MiB/s, done.\n","Resolving deltas: 100% (525/525), done.\n"]}],"source":["!git clone https://github.com/AdimadLp/arc_benchmark_tutorial.git"]},{"cell_type":"code","source":["cd arc_benchmark_tutorial"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFdMfBMvBSXY","executionInfo":{"status":"ok","timestamp":1705061566543,"user_tz":-60,"elapsed":449,"user":{"displayName":"AdimadLp","userId":"05864867446893575020"}},"outputId":"6a3f3374-4e4f-4fe9-956d-2ab1eacabbcb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/arc_benchmark_tutorial\n"]}]},{"cell_type":"code","source":["!gdown https://drive.google.com/drive/folders/1Cpr6vu_jD1E5GwE9r_SOIFDZUye9WrEh?usp=sharing"],"metadata":{"id":"grchNwmYmMV0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import train_gpt2"],"metadata":{"id":"cs1w_uZyCt6Q","executionInfo":{"status":"ok","timestamp":1705061573583,"user_tz":-60,"elapsed":5439,"user":{"displayName":"AdimadLp","userId":"05864867446893575020"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["model_path = \"gpt2_medium_2e-05_10\"\n","learning_rate = float(model_path.split('_')[-2])\n","epoch = int(model_path.split('_')[-1])\n","batch_size = 1"],"metadata":{"id":"uEGjsKrFBYeJ","executionInfo":{"status":"ok","timestamp":1705048349538,"user_tz":-60,"elapsed":17,"user":{"displayName":"AdimadLp","userId":"05864867446893575020"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train(model_path, learning_rate, batch_size, epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a1038ea37e834c628fcf38fec71c133a","52fa5078b420481da4113b0d0e0edc21","e1f18eb7c0b74f7289f988b33015460a","663b72ad00bc490cbcd6bc294f43904d","8f320dc41de24b05a0e15d4fcc9e04c6","1fd668c5710444c68092ade8202e1f36","e9ab00d2fa38433ca1e9ad58a6179b32","9b64bd80c592492e897977d840c477a4","82f2ee38d67d43bc9af915346a3c2f9a","3b4142b4d2f0429fa5d7bb74dd71769a","ba2b2b9f8de64a4886a8d2cdb5059afb","24d3924ef1e940d183bf30d981834cfa","b5ac3c21cbde40a488e2cc4f945ac8e4","77dd71eebc8a4f48acdfa3d9ec9c1bc1","7c15e8d8253b4f2eb200c388b67aa86f","6f9cc3dffe60409ab75e0c327dfed300","2d2a8c50e98d43d3ab59c521dc7616ec","846a66e6a2614600b66dbb665fdfe937","213e57b93c5741379f4f0d3e5b3f77e8","61642a4871144c6ea912c776669bcc89","7fe107b890f64716952deca216f5fd4f","e22a63d00f784478b6234786e470b796","4502ac73bc84410eb2af0da63e1a81dd","a6fc39753c1f47d992214ad0e605b858","a9ec11f58f8a45cdaadd8f6abfe2d0e2","d91977ef1d17432d9085647a95f1e6e1","5a168f68a1d14f5c887eeae5b89b9b0b","b798b2abdf0841418c4ad46c83683c76","405d150e9c074f0d965211742cffbacf","b00762c111d74d9eb88e009387eb7bb1","e5056bc9b0d3473cb9c6e513db5691ad","80ba65468725465f92cf6b09ffd057a8","d915a92a723f40ac89eef3ef0cb68aa9","3d989a4a34434f1bb76245d58d45a7fd","0e6530d60a524f27bcce310167e80930","39b6cf4e1b934ca9af94d54de24ea20f","b834d97adf0f42edbf089d503cd1e023","f98aab0ea0b6485a93e1779360507f19","9a401b61f37c49f1863c2a7ab62bced8","4bac9f92088748c4b91b5ada96b84a58","a89dd5bc876d419faf8f0984e1ab7dbe","5e5eef070d1748b094e9eb36b3a60cd0","3efd8d5b1e32451ea104341bf4803b0b","74c3dc0934e04a21901b0dcfe6c0a9e4","53f05ef1220c45abb62c51fa64a6c8f9","add9957add60434b8b4d01b1dde49af2","b5e701abc08f4cbd8c57b64ee0edf43c","45ae0f57357f48208427a28487561278","df9ce5663d0845eeb6880a21d5612d3b","1cecf73529764df0af8bb7c68684d114","9939d27e494047eb9621f0f647f00f68","c768f7a1249d43009a58ec24a55573e7","061e5af6f56a40b7aebad0a8fa206ca4","3c6b4c3945f24ee9970a335bd0c87d57","262748c1476f43658ac941e6898ac4d9","05c721290c8e4f878ee7e0335bebeacf","3477cf4b96f945fe94d4972710f7bee7","10e9e8cf54814c348ee2500da0d522d7","15c0ca2daf974d6c8f4932e496e1956a","2ca831c8eb5f4ff48e48934873965d36","0a9ffe84a1db48ca8decd4b482862df7","ee099bf379de40249c085834baad3356","544ef8f435b14f17a57ed7f24913cc90","31b120cad708469183060cc38bb7eef0","c62325b2ae3e493c85111706ec2173f4","942001eab83d48ebb921cd88f9e1b81d"]},"id":"FCPOB3OiCb7T","outputId":"e6efffdd-53b4-41f0-cac3-dc12dec2aa74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model_path: gpt2-medium\n","learning_rate: 2e-05\n","batch_size: 1\n","epoch: 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1038ea37e834c628fcf38fec71c133a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24d3924ef1e940d183bf30d981834cfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4502ac73bc84410eb2af0da63e1a81dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d989a4a34434f1bb76245d58d45a7fd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokenizer loaded\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f05ef1220c45abb62c51fa64a6c8f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05c721290c8e4f878ee7e0335bebeacf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model loaded\n","Taining data loaded\n","Evaluation data loaded\n","Start training...\n","Step 10, Loss: 1.7481328248977661\n","Step 20, Loss: 0.2831794321537018\n","Step 30, Loss: 0.28355640172958374\n","Step 40, Loss: 0.3023172914981842\n","Step 50, Loss: 0.3716605305671692\n","Step 60, Loss: 0.37216195464134216\n","Step 70, Loss: 0.24987202882766724\n","Step 80, Loss: 0.22009220719337463\n","Step 90, Loss: 0.3548031449317932\n","Step 100, Loss: 0.29224902391433716\n","Step 110, Loss: 0.3706096112728119\n","Step 120, Loss: 0.3255893886089325\n","Step 130, Loss: 0.2211596816778183\n","Step 140, Loss: 1.1639589071273804\n","Step 150, Loss: 0.1851358860731125\n","Step 160, Loss: 0.3083287179470062\n","Step 170, Loss: 0.28619930148124695\n","Step 180, Loss: 0.35630708932876587\n","Step 190, Loss: 0.32821792364120483\n","Step 200, Loss: 0.2696057856082916\n","Step 210, Loss: 0.10135959833860397\n","Step 220, Loss: 0.32255470752716064\n","Step 230, Loss: 0.1873215138912201\n","Step 240, Loss: 0.1544521301984787\n","Step 250, Loss: 0.3282449245452881\n","Step 260, Loss: 0.2505083680152893\n","Step 270, Loss: 0.20415110886096954\n","Step 280, Loss: 0.27098435163497925\n","Step 290, Loss: 0.1420786827802658\n","Step 300, Loss: 0.1425056904554367\n","Step 310, Loss: 0.3795369267463684\n","Step 320, Loss: 0.3962424099445343\n","Step 330, Loss: 0.1848621666431427\n","Step 340, Loss: 0.41519075632095337\n","Step 350, Loss: 0.13940665125846863\n","Step 360, Loss: 0.12797662615776062\n","Step 370, Loss: 0.2903342545032501\n","Step 380, Loss: 0.276322603225708\n","Step 390, Loss: 0.11394359171390533\n","Step 400, Loss: 0.11051583290100098\n","Epoch 1 completed with loss 0.11051583290100098\n","Output data has different lengths: [[4, 5, 4, 4, 4, 4, 3, 5], [4, 5, 4, 4, 4, 4, 3, 5], [7, 7, 8, 7], [7, 7, 8, 7], [8, 8, 7, 8], [5, 4, 5, 8]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[7, 7, 8, 8, 7, 7, 7, 7], [7, 7, 8, 8, 7, 7, 7, 7], [7, 7, 8, 8, 7, 7, 7, 7], [5, 8, 5, 5, 8, 5, 8, 5], [7, 7, 8, 8, 7, 7, 7, 7], [7, 7, 8, 8, 7, 7, 7, 7], [5, 8, 5, 5, 8, 5, 8, 5], [7, 7, 8, 8, 7, 7, 7, 7], [7, 7, 8, 8, 7, 7, 7, 7], [5, 8, 5, 5, 8, 5, 8, 5], [7, 7, 8, 8, 7, 7, 7, 7]]\n","Input: [[3, 3, 5, 3], [5, 4, 5, 4], [5, 5, 3, 3], [7, 7, 8, 7], [7, 7, 8, 7], [8, 8, 7, 8], [5, 4, 5, 8]] Output: [[4, 5, 4, 4, 4, 4, 3, 5], [4, 5, 4, 4, 4, 4, 3, 5], [7, 7, 8, 7], [7, 7, 8, 7], [8, 8, 7, 8], [5, 4, 5, 8]]\n","Input: [[6, 2, 7, 6, 4], [8, 7, 8, 2], [5, 5, 3, 7], [6, 2, 7, 6], [8, 7, 8, 7]] Output: [[7, 7, 8, 7, 7, 7, 7, 7], [7, 7, 8, 7, 7, 7, 7, 7], [7, 7, 8, 7, 7, 7, 7, 7], [8, 8, 7, 7, 7, 7, 7, 7], [5, 5, 3, 7, 7, 7, 7, 7], [6, 2, 7, 6, 4, 4, 6], [8, 7, 8, 2], [5, 5, 3, 7], [6, 2, 7, 6, 4], [8, 7, 8, 2], [5, 5, 3, 7], [6, 2, 7, 6, 4, 4, 6], [8, 7, 8, 2], [5, 5, 3, 7], [6, 2, 7, 6, 4], [ 8, 7, 8, 7], [5, 5, 3, 7], [6, 2,\n","Output data has different lengths: [[8, 7, 7, 7, 8, 8, 5, 8], [8, 7, 7, 7, 7, 7, 7, 7], [5, 5, 7, 8, 8], [8, 8, 8, 8, 8, 8, 5, 7], [5, 5, 7, 8, 8], [7, 7, 8, 8, 8, 7, 7, 7], [5, 5, 7, 8, 8, 7, 7, 7], [8, 7, 7, 7, 7, 7, 7, 7], [8, 7, 7, 7, 7, 7, 7, 7], [5, 5, 7, 8, 8], [8, 8, 8, 8, 8, 8, 5, 7], [5, 5, 7, 8, 8, 7, 7, 7], [7, 7, 8, 8, 8, 7, 7, 7], [5, 5, 7, 8, 8, 7, 7, 7]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[8, 7, 7, 7, 8, 8, 5, 8], [8, 7, 7, 7, 7, 7, 7, 7], [5, 5, 7, 8, 8], [8, 8, 8, 8, 8, 8, 5, 7], [5, 5, 7, 8, 8], [7, 7, 8, 8, 8, 7, 7, 7], [5, 5, 7, 8, 8, 7, 7, 7], [8, 7, 7, 7, 7, 7, 7, 7], [8, 7, 7, 7, 7, 7, 7, 7], [5, 5, 7, 8, 8], [8, 8, 8, 8, 8, 8, 5, 7], [5, 5, 7, 8, 8, 7, 7, 7], [7, 7, 8, 8, 8, 7, 7, 7], [5, 5, 7, 8, 8, 7, 7, 7]]\n","Output data has different lengths: [[5, 5, 5, 8, 8, 5, 7, 7], [8, 5, 7, 8, 8, 8, 7, 7], [7, 7, 8, 8, 8, 7, 7], [5, 5, 8, 5, 8, 8, 7, 7], [8, 5, 7, 8, 8, 7, 7, 7], [5, 5, 7, 8, 8, 7, 7, 7], [5, 5, 7, 8, 8, 7, 7, 7]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[5, 5, 5, 8, 8, 5, 7, 7], [8, 5, 7, 8, 8, 8, 7, 7], [7, 7, 8, 8, 8, 7, 7], [5, 5, 8, 5, 8, 8, 7, 7], [8, 5, 7, 8, 8, 7, 7, 7], [5, 5, 7, 8, 8, 7, 7, 7], [5, 5, 7, 8, 8, 7, 7, 7]]\n","Input: [[4, 4, 2, 5], [4, 4, 9, 9], [3, 4, 7, 8]] Output: [[4, 4, 4, 9, 9], [9, 4, 9, 9], [4, 4, 4, 9, 9], [3, 4, 7, 8], [9, 4, 9, 9], [4, 4, 4, 9, 9], [3, 4, 7, 8], [9, 4, 9, 9], [4, 4, 4, 9, 9], [3, 4, 7, 8]]\n","Input: [[5, 6, 9, 9], [2, 6, 3, 2]] Output: [[6, 2, 6, 6], [6, 2, 6, 6], [2, 6, 3, 2]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7], [9, 5, 5, 5]] Output: [[5, 5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7], [9, 5, 5, 5], [2, 6, 3, 2], [3, 4, 7, 8], [9, 5, 5, 5]]\n","Visualizing example 4 of model arc_model_2e-05_1\n","Output data has different lengths: [[8, 5, 7, 8, 7, 7, 8, 7, 8], [7, 7, 8, 8, 7, 7, 7, 8, 7], [7, 7, 8, 8, 7, 7, 7, 8, 7], [5, 5, 8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 7, 8, 7, 7, 7, 7, 8, 7], [7, 7, 7, 8, 7, 7, 7, 8, 7], [5, 5, 8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 7, 8, 7, 7, 7, 8, 7], [7, 7, 7, 8, 7, 7, 7, 8, 7], [5, 5, 8, 5, 8, 8, 8, 8, 5, 8]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[8, 5, 7, 8, 7, 7, 8, 7, 8], [7, 7, 8, 8, 7, 7, 7, 8, 7], [7, 7, 8, 8, 7, 7, 7, 8, 7], [5, 5, 8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 7, 8, 7, 7, 7, 7, 8, 7], [7, 7, 7, 8, 7, 7, 7, 8, 7], [5, 5, 8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 7, 8, 7, 7, 7, 8, 7], [7, 7, 7, 8, 7, 7, 7, 8, 7], [5, 5, 8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 8, 5, 5], [5, 5, 5, 8]] Output: [[8, 5, 5, 5, 8], [5, 5, 5, 5, 8], [8, 8, 5, 5, 5], [5, 5, 5, 8, 5], [8, 8, 5, 5, 5], [5, 5, 5, 8, 5], [8, 8, 5, 5, 5]]\n","Input: [[7, 5, 5, 5, 7], [5, 5, 7, 5, 5], [5, 5, 7, 7, 7], [7, 7, 7, 7, 7]] Output: [[7, 5, 7, 7, 7], [5, 5, 7, 7, 7], [7, 7, 7, 7, 7], [5, 5, 7, 7, 7], [7, 7, 7, 7, 7], [5, 5, 7, 7, 7], [7, 7, 7, 7, 7]]\n","Step 10, Loss: 0.14941178262233734\n","Step 20, Loss: 0.07972145080566406\n","Step 30, Loss: 0.19316892325878143\n","Step 40, Loss: 0.5975156426429749\n","Step 50, Loss: 0.16689597070217133\n","Step 60, Loss: 0.18023498356342316\n","Step 70, Loss: 0.24089296162128448\n","Step 80, Loss: 0.2813105285167694\n","Step 90, Loss: 0.4393717348575592\n","Step 100, Loss: 1.1049234867095947\n","Step 110, Loss: 0.1589105874300003\n","Step 120, Loss: 0.34426555037498474\n","Step 130, Loss: 0.37521493434906006\n","Step 140, Loss: 0.18059225380420685\n","Step 150, Loss: 0.31349825859069824\n","Step 160, Loss: 0.13902024924755096\n","Step 170, Loss: 0.16094870865345\n","Step 180, Loss: 0.17264841496944427\n","Step 190, Loss: 0.20671959221363068\n","Step 200, Loss: 0.19959917664527893\n","Step 210, Loss: 0.16378076374530792\n","Step 220, Loss: 0.10317900031805038\n","Step 230, Loss: 0.19261611998081207\n","Step 240, Loss: 0.2112915813922882\n","Step 250, Loss: 0.2333383709192276\n","Step 260, Loss: 0.4471661448478699\n","Step 270, Loss: 0.2818496525287628\n","Step 280, Loss: 0.5309491753578186\n","Step 290, Loss: 0.24457797408103943\n","Step 300, Loss: 0.2322259396314621\n","Step 310, Loss: 0.5933446884155273\n","Step 320, Loss: 0.20876893401145935\n","Step 330, Loss: 0.29550760984420776\n","Step 340, Loss: 0.23421888053417206\n","Step 350, Loss: 0.2591553330421448\n","Step 360, Loss: 0.2727363705635071\n","Step 370, Loss: 0.32810384035110474\n","Step 380, Loss: 0.15131625533103943\n","Step 390, Loss: 0.2632993757724762\n","Step 400, Loss: 0.17932847142219543\n","Epoch 2 completed with loss 0.17932847142219543\n","Output data has different lengths: [[5, 5, 5, 5, 5, 5, 5, 5], [1, 2, 3, 5, 5, 1, 2], [2, 2, 3, 5, 5, 2, 2], [1, 2, 5, 3, 5, 1, 2], [5, 5, 5, 5, 5, 5, 5, 5]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[8, 5, 7, 8, 8, 8, 5, 7], [7, 7, 8, 8, 8, 7, 8, 8], [5, 5, 8, 5, 8, 5, 5, 5], [5, 8, 5, 5, 5, 8, 5, 8], [5, 7, 5, 5, 5, 7, 5, 7], [5, 5, 5, 8, 5, 5, 5, 5]]\n","Input: [[1, 2, 5, 3], [5, 5, 5, 5], [5, 5, 5, 5]] Output: [[5, 5, 5, 5, 5, 5, 5, 5], [1, 2, 3, 5, 5, 1, 2], [2, 2, 3, 5, 5, 2, 2], [1, 2, 5, 3, 5, 1, 2], [5, 5, 5, 5, 5, 5, 5, 5]]\n","Visualizing example 2 of model arc_model_2e-05_2\n","Output data has different lengths: [[6, 4, 8, 8, 4, 8, 6, 4], [6, 4, 2, 6, 6, 4, 2], [4, 6, 4, 8, 8, 4, 4, 4], [6, 4, 8, 2, 2, 2, 2, 6], [6, 4, 2, 2, 2, 2, 6, 6], [4, 4, 4, 8, 8, 4, 4, 4], [6, 4, 4, 8, 8, 4, 8, 6], [8, 7, 7, 7, 7, 7, 8, 7]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[5, 7, 5, 5, 5, 5, 7, 7], [8, 5, 8, 8, 8, 5, 7, 8], [8, 5, 8, 5, 5, 8, 8, 5], [7, 7, 8, 8, 8, 7, 7, 8], [8, 8, 8, 5, 5, 8, 8, 8], [7, 7, 5, 5, 5, 7, 5, 5]]\n","Input: [[6, 4, 4, 8], [6, 4, 3, 6], [6, 4, 4, 8]] Output: [[6, 4, 8, 8, 4, 8, 6, 4], [6, 4, 2, 6, 6, 4, 2], [4, 6, 4, 8, 8, 4, 4, 4], [6, 4, 8, 2, 2, 2, 2, 6], [6, 4, 2, 2, 2, 2, 6, 6], [4, 4, 4, 8, 8, 4, 4, 4], [6, 4, 4, 8, 8, 4, 8, 6], [8, 7, 7, 7, 7, 7, 8, 7]]\n","Output data has different lengths: [[5, 5, 8, 5, 5, 5, 8, 8], [7, 7, 8, 8, 8, 7, 7, 8], [7, 5, 8, 5, 5, 5, 7, 8], [5, 5, 8, 5, 5, 7, 8, 5], [8, 5, 7, 8, 8, 8, 8, 7, 8], [8, 7, 8, 8, 8, 7, 7, 8]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[5, 5, 8, 5, 5, 5, 8, 8], [7, 7, 8, 8, 8, 7, 7, 8], [7, 5, 8, 5, 5, 5, 7, 8], [5, 5, 8, 5, 5, 7, 8, 5], [8, 5, 7, 8, 8, 8, 8, 7, 8], [8, 7, 8, 8, 8, 7, 7, 8]]\n","Input: [[5, 5, 6, 9, 9], [2, 6, 4, 2, 1], [6, 6, 2, 6, 6], [6, 6, 6, 6, 2], [2, 5, 2, 5, 5], [4, 6, 2, 2, 2], [2, 2, 2, 6, 6]] Output: [[6, 6, 2, 6, 6, 6, 2, 6], [5, 5, 5, 5, 5, 2, 5, 2], [5, 5, 2, 2, 2, 2, 5, 5], [5, 5, 2, 2, 2, 2, 5, 5], [8, 5, 7, 7, 7, 8, 7, 8], [8, 8, 5, 7, 7, 8, 5, 8], [8, 5, 7, 7, 7, 8, 5, 8], [6, 6, 6, 6, 6, 2, 2, 2]]\n","Input: [[6, 5, 5, 5, 5], [1, 1, 1, 1, 5], [2, 5, 2, 5, 5], [4, 6, 2, 2, 2], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [5, 5, 5, 5, 5], [7, 5, 5, 7, 7]] Output: [[4, 6, 2, 2, 2, 5, 5, 5], [4, 6, 2, 2, 2, 2, 5, 5], [5, 5, 5, 5, 5, 5], [1, 1, 1, 1, 5], [2, 2, 2, 2, 2, 2], [5, 5, 5, 5, 5, 5], [7, 5, 5, 7, 7], [7, 7, 7, 7, 7], [5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5], [6, 6, 6, 6, 6], [6, 6, 6, 6, 6]]\n","Input: [[4, 6, 6, 2, 6], [8, 8, 5, 7\n","Visualizing example 5 of model arc_model_2e-05_2\n","Step 10, Loss: 0.2599513530731201\n","Step 20, Loss: 0.14972300827503204\n","Step 30, Loss: 0.1356627345085144\n","Step 40, Loss: 0.21542775630950928\n","Step 50, Loss: 0.18253593146800995\n","Step 60, Loss: 0.2064041942358017\n","Step 70, Loss: 0.11365809291601181\n","Step 80, Loss: 0.16574141383171082\n","Step 90, Loss: 0.19130708277225494\n","Step 100, Loss: 0.11887287348508835\n","Step 110, Loss: 0.3859982192516327\n","Step 120, Loss: 0.11978141218423843\n","Step 130, Loss: 0.11494000256061554\n","Step 140, Loss: 0.2063976675271988\n","Step 150, Loss: 0.1406269073486328\n","Step 160, Loss: 0.08762648701667786\n","Step 170, Loss: 0.14429184794425964\n","Step 180, Loss: 0.31993257999420166\n","Step 190, Loss: 0.26245981454849243\n","Step 200, Loss: 0.1642909049987793\n","Step 210, Loss: 0.3246822655200958\n","Step 220, Loss: 0.1903097927570343\n","Step 230, Loss: 0.9434736371040344\n","Step 240, Loss: 0.39971619844436646\n","Step 250, Loss: 0.11645776778459549\n","Step 260, Loss: 0.19212821125984192\n","Step 270, Loss: 0.25163596868515015\n","Step 280, Loss: 0.12990188598632812\n","Step 290, Loss: 0.2206583470106125\n","Step 300, Loss: 0.15952491760253906\n","Step 310, Loss: 0.15751777589321136\n","Step 320, Loss: 0.08292927592992783\n","Step 330, Loss: 0.1885625422000885\n","Step 340, Loss: 0.49863600730895996\n","Step 350, Loss: 0.28073084354400635\n","Step 360, Loss: 0.21998442709445953\n","Step 370, Loss: 0.2657386064529419\n","Step 380, Loss: 0.21737411618232727\n","Step 390, Loss: 0.27939677238464355\n","Step 400, Loss: 0.13634948432445526\n","Epoch 3 completed with loss 0.13634948432445526\n","Output data has different lengths: [[2, 2, 2, 5, 2, 8, 2, 8, 2], [6, 2, 8, 2, 2, 2, 6, 2, 8, 2], [8, 8, 8, 5, 2, 4, 8, 8, 5, 2], [5, 5, 8, 5, 8, 6, 3, 5, 8, 5], [6, 2, 8, 2, 2, 2, 6, 2, 8, 2], [8, 8, 8, 5, 2, 4, 8, 8, 5, 2], [8, 8, 3, 5, 6, 3, 8, 3, 5, 2], [8, 8, 5, 2, 4, 8, 3, 5, 8, 5], [6, 2, 8, 2, 2, 2, 6, 2, 8, 2], [8, 8, 2, 8, 2, 2, 6, 2, 8, 2]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[5, 5, 8, 5, 7, 7, 5, 5], [8, 8, 7, 8, 7, 8, 5, 8], [5, 5, 7, 8, 8, 7, 5, 5], [8, 8, 7, 8, 7, 8, 5, 8]]\n","Input: [[6, 2, 8, 2, 2], [8, 8, 5, 2, 4], [8, 5, 3, 5, 6]] Output: [[2, 2, 2, 5, 2, 8, 2, 8, 2], [6, 2, 8, 2, 2, 2, 6, 2, 8, 2], [8, 8, 8, 5, 2, 4, 8, 8, 5, 2], [5, 5, 8, 5, 8, 6, 3, 5, 8, 5], [6, 2, 8, 2, 2, 2, 6, 2, 8, 2], [8, 8, 8, 5, 2, 4, 8, 8, 5, 2], [8, 8, 3, 5, 6, 3, 8, 3, 5, 2], [8, 8, 5, 2, 4, 8, 3, 5, 8, 5], [6, 2, 8, 2, 2, 2, 6, 2, 8, 2], [8, 8, 2, 8, 2, 2, 6, 2, 8, 2]]\n","Input: [[8, 6, 5, 9], [2, 5, 3, 8]] Output: [[8, 5, 3, 8, 5, 8, 6, 5, 3, 8], [2, 5, 3, 8, 5, 8, 6, 5, 3, 8], [8, 5, 3, 8, 5, 8, 6, 5, 3, 8], [5, 5, 8, 5, 8, 6, 5, 3, 5, 8], [8, 5, 8, 5, 8, 6, 5, 3, 5, 8], [5, 5, 8, 5, 8, 6, 5, 3, 5, 8], [2, 5, 3, 8, 5, 8, 6, 5, 3, 8], [8, 5, 3, 8, 5, 8, 6, 5, 3, 8]]\n","Input: [[8, 8, 5, 2, 4], [5, 3, 3, 8], [5, 3, 5, 5]] Output: [[5, 5, 3, 8, 5, 8, 5, 3, 3], [8, 8, 5, 2, 4, 8, 6, 5, 3, 8], [5, 5, 3, 8, 5, 8\n","Output data has different lengths: [[3, 6, 9, 6, 6, 6, 3, 6, 9], [3, 6, 9, 6, 6, 6, 6, 3, 6, 9], [3, 6, 9, 6, 6, 6, 6, 3, 6, 9], [6, 6, 3, 3, 3, 3, 3, 5, 5], [3, 6, 9, 6, 6, 6, 6, 3, 6, 9], [6, 6, 3, 3, 3, 3, 3, 5, 5]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[8, 7, 7, 5, 7, 7, 5, 8], [8, 7, 7, 5, 7, 7, 5, 8], [7, 7, 8, 8, 8, 7, 5, 7], [5, 5, 8, 5, 5, 8, 7, 5], [5, 8, 5, 8, 5, 8, 8, 8]]\n","Input: [[3, 6, 9, 5], [3, 3, 6, 9], [7, 5, 7, 5], [5, 8, 3, 5]] Output: [[3, 6, 9, 6, 6, 6, 3, 6, 9], [3, 6, 9, 6, 6, 6, 6, 3, 6, 9], [3, 6, 9, 6, 6, 6, 6, 3, 6, 9], [6, 6, 3, 3, 3, 3, 3, 5, 5], [3, 6, 9, 6, 6, 6, 6, 3, 6, 9], [6, 6, 3, 3, 3, 3, 3, 5, 5]]\n","Output data has different lengths: [[7, 8, 5, 8, 8, 7, 8, 5, 8], [7, 7, 8, 8, 8, 7, 7, 7], [5, 5, 8, 5, 8, 5, 5, 8], [8, 8, 5, 8, 5, 5, 8, 5], [8, 8, 5, 8, 5, 5, 8, 5]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[7, 8, 5, 8, 8, 7, 8, 5, 8], [7, 7, 8, 8, 8, 7, 7, 7], [5, 5, 8, 5, 8, 5, 5, 8], [8, 8, 5, 8, 5, 5, 8, 5], [8, 8, 5, 8, 5, 5, 8, 5]]\n","Input: [[2, 4, 5, 3, 3], [3, 3, 9, 8, 3], [3, 3, 3, 5, 5]] Output: [[5, 3, 9, 5, 5, 5, 3, 9, 5], [2, 4, 5, 3, 3, 2, 4, 5], [3, 3, 3, 5, 5, 3, 3, 9], [3, 3, 3, 5, 5, 3, 3, 9], [5, 3, 9, 5, 5, 5, 3, 9, 5], [2, 4, 5, 3, 3, 2, 4, 5], [3, 3, 9, 8, 3, 3, 3, 3]]\n","Output data has different lengths: [[7, 8, 5, 7, 8, 5, 7, 8], [7, 7, 8, 8, 8, 7, 8, 5, 8], [5, 5, 8, 5, 5, 8, 5, 8], [8, 8, 5, 7, 8, 7, 8, 5, 8], [8, 8, 5, 7, 8, 7, 8, 5, 8]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[7, 8, 5, 7, 8, 5, 7, 8], [7, 7, 8, 8, 8, 7, 8, 5, 8], [5, 5, 8, 5, 5, 8, 5, 8], [8, 8, 5, 7, 8, 7, 8, 5, 8], [8, 8, 5, 7, 8, 7, 8, 5, 8]]\n","Input: [[6, 7, 5, 5], [7, 8, 7, 5], [5, 7, 7, 5]] Output: [[6, 7, 6, 5, 7, 6, 7, 5, 7], [7, 7, 7, 7, 8, 7, 8, 5, 7], [5, 7, 7, 5, 7, 7, 8, 5, 7], [5, 7, 7, 7, 8, 7, 8, 5, 7], [7, 7, 7, 8, 8, 7, 8, 5, 7]]\n","Input: [[2, 3, 8, 5], [6, 5, 6, 3], [3, 3, 5, 3]] Output: [[2, 3, 3, 5, 2, 3, 8, 5, 6], [5, 6, 6, 5, 6, 5, 6, 5, 6], [3, 3, 5, 3, 5, 3, 3, 5, 3], [6, 5, 6, 3, 5, 2, 3, 8, 5, 6], [3, 3, 5, 3, 5, 3, 3, 5, 3], [5, 6, 6, 5, 6, 5, 6, 5, 6], [3, 3, 5, 3, 5, 3, 3, 5, 3], [2, 3, 3, 5, 2, 3, 8, 5, 6]]\n","Input: [[2, 3, 8, 4], [3, 5, 5, 4], [3, 3, 5, 3]] Output: [[2, 3, 3, 5, 2, 3, 8, 5, 6], [5, 6, 6, 5, 6, 5, 6, 5, 6], [3, 3, 5, 3, 5, 3, 3, 5, 3], [2, 3, 3, 5, 2, 3, 8, 5, 6], [5, 6, 6, 5, 6, 5, 6, 5, 6], [3, 3, 5, 3, 5, 3, 3, 5, 3], [6, 5, 6, 5, 6, 5, 6, 5, 6], [3, 3, 5, 3, 5, 3, 3, 5, 3], [2,\n","Visualizing example 5 of model arc_model_2e-05_3\n","Step 10, Loss: 0.12347635626792908\n","Step 20, Loss: 0.1457611322402954\n","Step 30, Loss: 0.3889903724193573\n","Step 40, Loss: 0.25774896144866943\n","Step 50, Loss: 0.191859170794487\n","Step 60, Loss: 0.11379075795412064\n","Step 70, Loss: 0.29472607374191284\n","Step 80, Loss: 0.15157820284366608\n","Step 90, Loss: 0.13095790147781372\n","Step 100, Loss: 0.2621324062347412\n","Step 110, Loss: 0.15159901976585388\n","Step 120, Loss: 0.14123015105724335\n","Step 130, Loss: 0.1637769192457199\n","Step 140, Loss: 0.1529989242553711\n","Step 150, Loss: 0.15436547994613647\n","Step 160, Loss: 0.07995034009218216\n","Step 170, Loss: 0.20188504457473755\n","Step 180, Loss: 0.20049627125263214\n","Step 190, Loss: 0.08775033056735992\n","Step 200, Loss: 0.24023698270320892\n","Step 210, Loss: 0.2575927674770355\n","Step 220, Loss: 0.1422351896762848\n","Step 230, Loss: 0.2810989320278168\n","Step 240, Loss: 0.18372923135757446\n","Step 250, Loss: 0.1235613152384758\n","Step 260, Loss: 0.1751202791929245\n","Step 270, Loss: 0.21147476136684418\n","Step 280, Loss: 0.1886034905910492\n","Step 290, Loss: 0.2051890343427658\n","Step 300, Loss: 0.1254764050245285\n","Step 310, Loss: 0.15879879891872406\n","Step 320, Loss: 0.21226465702056885\n","Step 330, Loss: 0.1523963063955307\n","Step 340, Loss: 0.21393176913261414\n","Step 350, Loss: 0.5064494609832764\n","Step 360, Loss: 0.2912052273750305\n","Step 370, Loss: 0.17581117153167725\n","Step 380, Loss: 0.12371241301298141\n","Step 390, Loss: 0.24731753766536713\n","Step 400, Loss: 1.0810099840164185\n","Epoch 4 completed with loss 1.0810099840164185\n","Visualizing example 1 of model arc_model_2e-05_4\n","Visualizing example 2 of model arc_model_2e-05_4\n","Output data has different lengths: [[7, 7, 8, 8, 8, 8, 7, 8, 5, 5], [7, 7, 8, 8, 8, 8, 7, 8, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[7, 7, 8, 8, 8, 8, 7, 8, 5, 5], [7, 7, 8, 8, 8, 8, 7, 8, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5]]\n","Visualizing example 4 of model arc_model_2e-05_4\n","Visualizing example 5 of model arc_model_2e-05_4\n","Step 10, Loss: 0.277782678604126\n","Step 20, Loss: 0.10721607506275177\n","Step 30, Loss: 0.3857410252094269\n","Step 40, Loss: 0.19740912318229675\n","Step 50, Loss: 0.23567304015159607\n","Step 60, Loss: 0.23956897854804993\n","Step 70, Loss: 0.16790203750133514\n","Step 80, Loss: 0.6059215068817139\n","Step 90, Loss: 0.21398669481277466\n","Step 100, Loss: 0.10415081679821014\n","Step 110, Loss: 0.5265865325927734\n","Step 120, Loss: 0.18392150104045868\n","Step 130, Loss: 0.16740918159484863\n","Step 140, Loss: 0.12003474682569504\n","Step 150, Loss: 0.1281813085079193\n","Step 160, Loss: 0.14485476911067963\n","Step 170, Loss: 0.10094058513641357\n","Step 180, Loss: 0.07793289422988892\n","Step 190, Loss: 0.26031166315078735\n","Step 200, Loss: 0.19148507714271545\n","Step 210, Loss: 0.06608905643224716\n","Step 220, Loss: 0.4665011167526245\n","Step 230, Loss: 0.11435473710298538\n","Step 240, Loss: 0.15025024116039276\n","Step 250, Loss: 0.2376597374677658\n","Step 260, Loss: 0.21716001629829407\n","Step 270, Loss: 0.2481265813112259\n","Step 280, Loss: 0.14557629823684692\n","Step 290, Loss: 0.10534489154815674\n","Step 300, Loss: 0.2007346898317337\n","Step 310, Loss: 0.3661189675331116\n","Step 320, Loss: 0.09582257270812988\n","Step 330, Loss: 0.1288420557975769\n","Step 340, Loss: 0.18852074444293976\n","Step 350, Loss: 0.23315474390983582\n","Step 360, Loss: 0.2301447093486786\n","Step 370, Loss: 0.15814179182052612\n","Step 380, Loss: 0.07932203263044357\n","Step 390, Loss: 0.2611337900161743\n","Step 400, Loss: 0.2519432306289673\n","Epoch 5 completed with loss 0.2519432306289673\n","Visualizing example 1 of model arc_model_2e-05_5\n","Visualizing example 2 of model arc_model_2e-05_5\n","Visualizing example 3 of model arc_model_2e-05_5\n","Visualizing example 4 of model arc_model_2e-05_5\n","Output data has different lengths: [[8, 5, 7, 8, 8, 8, 5, 7, 8], [7, 7, 8, 8, 8, 7, 7, 8], [7, 7, 8, 8, 7, 7, 7, 8], [5, 5, 8, 5, 8, 8, 5, 7, 8], [8, 5, 7, 8, 8, 8, 5, 7, 8], [8, 5, 7, 8, 8, 7, 7, 8], [8, 5, 7, 8, 8, 7, 7, 8]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[8, 5, 7, 8, 8, 8, 5, 7, 8], [7, 7, 8, 8, 8, 7, 7, 8], [7, 7, 8, 8, 7, 7, 7, 8], [5, 5, 8, 5, 8, 8, 5, 7, 8], [8, 5, 7, 8, 8, 8, 5, 7, 8], [8, 5, 7, 8, 8, 7, 7, 8], [8, 5, 7, 8, 8, 7, 7, 8]]\n","Step 10, Loss: 0.11901230365037918\n","Step 20, Loss: 0.15562020242214203\n","Step 30, Loss: 0.12303179502487183\n","Step 40, Loss: 0.2011619359254837\n","Step 50, Loss: 0.14335337281227112\n","Step 60, Loss: 0.13500773906707764\n","Step 70, Loss: 0.106723353266716\n","Step 80, Loss: 0.4087497293949127\n","Step 90, Loss: 0.18286509811878204\n","Step 100, Loss: 0.21869924664497375\n","Step 110, Loss: 0.13070455193519592\n","Step 120, Loss: 0.29673606157302856\n","Step 130, Loss: 0.2433336228132248\n","Step 140, Loss: 0.13677427172660828\n","Step 150, Loss: 0.41181784868240356\n","Step 160, Loss: 0.16449715197086334\n","Step 170, Loss: 0.13257211446762085\n","Step 180, Loss: 0.1579088419675827\n","Step 190, Loss: 0.16004665195941925\n","Step 200, Loss: 0.12108134478330612\n","Step 210, Loss: 0.7294464707374573\n","Step 220, Loss: 0.2268861085176468\n","Step 230, Loss: 0.1106964722275734\n","Step 240, Loss: 0.07215557247400284\n","Step 250, Loss: 0.12128569930791855\n","Step 260, Loss: 0.11077014356851578\n","Step 270, Loss: 0.23468433320522308\n","Step 280, Loss: 0.12690822780132294\n","Step 290, Loss: 0.09629270434379578\n","Step 300, Loss: 0.12783268094062805\n","Step 310, Loss: 0.18048903346061707\n","Step 320, Loss: 0.10059952735900879\n","Step 330, Loss: 0.23850049078464508\n","Step 340, Loss: 0.10103213042020798\n","Step 350, Loss: 0.16815364360809326\n","Step 360, Loss: 0.23358900845050812\n","Step 370, Loss: 0.16893823444843292\n","Step 380, Loss: 0.09086064994335175\n","Step 390, Loss: 0.3634478747844696\n","Step 400, Loss: 0.17699964344501495\n","Epoch 6 completed with loss 0.17699964344501495\n","Visualizing example 1 of model arc_model_2e-05_6\n","Visualizing example 2 of model arc_model_2e-05_6\n","Output data has different lengths: [[8, 5, 7, 8, 8, 8, 5, 7, 8], [7, 7, 8, 8, 8, 8, 7, 8, 7], [7, 7, 8, 8, 8, 8, 7, 8, 7], [5, 5, 7, 8, 8, 8, 8, 5, 7, 8], [8, 5, 7, 8, 8, 8, 7, 8, 7, 8], [5, 5, 8, 5, 8, 5, 5, 8, 5, 7], [7, 7, 8, 8, 8, 8, 7, 8, 8, 7], [8, 5, 7, 8, 8, 8, 7, 8, 7, 8]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[8, 5, 7, 8, 8, 8, 5, 7, 8], [7, 7, 8, 8, 8, 8, 7, 8, 7], [7, 7, 8, 8, 8, 8, 7, 8, 7], [5, 5, 7, 8, 8, 8, 8, 5, 7, 8], [8, 5, 7, 8, 8, 8, 7, 8, 7, 8], [5, 5, 8, 5, 8, 5, 5, 8, 5, 7], [7, 7, 8, 8, 8, 8, 7, 8, 8, 7], [8, 5, 7, 8, 8, 8, 7, 8, 7, 8]]\n","Input: [[1, 1, 5, 1], [4, 5, 1, 4], [8, 2, 5, 2]] Output: [[4, 5, 4, 5, 4, 5, 1, 1, 1], [1, 1, 5, 1, 1, 1, 1, 5, 4], [4, 5, 1, 4, 5, 4, 5, 1, 1], [8, 2, 5, 2, 5, 2, 5, 2, 2], [2, 5, 8, 3, 3, 3, 2, 8, 3], [8, 2, 5, 3, 3, 3, 2, 8, 3], [2, 5, 8, 3, 3, 3, 2, 8, 3], [1, 1, 5, 1, 1, 1, 1, 1, 1]]\n","Visualizing example 4 of model arc_model_2e-05_6\n","Visualizing example 5 of model arc_model_2e-05_6\n","Step 10, Loss: 0.1506747305393219\n","Step 20, Loss: 0.08908414095640182\n","Step 30, Loss: 0.13502974808216095\n","Step 40, Loss: 0.2070530652999878\n","Step 50, Loss: 0.06751394271850586\n","Step 60, Loss: 0.15459631383419037\n","Step 70, Loss: 0.19749028980731964\n","Step 80, Loss: 0.21253840625286102\n","Step 90, Loss: 0.06341012567281723\n","Step 100, Loss: 0.12643219530582428\n","Step 110, Loss: 0.577100932598114\n","Step 120, Loss: 0.18177008628845215\n","Step 130, Loss: 0.1255062371492386\n","Step 140, Loss: 0.2675439715385437\n","Step 150, Loss: 0.20627905428409576\n","Step 160, Loss: 0.1470937281847\n","Step 170, Loss: 0.2280575931072235\n","Step 180, Loss: 0.2916408181190491\n","Step 190, Loss: 0.1043035015463829\n","Step 200, Loss: 0.24625343084335327\n","Step 210, Loss: 0.11421963572502136\n","Step 220, Loss: 0.1046215370297432\n","Step 230, Loss: 0.12107540667057037\n","Step 240, Loss: 0.11075180023908615\n","Step 250, Loss: 0.17424874007701874\n","Step 260, Loss: 0.34627974033355713\n","Step 270, Loss: 0.2200159877538681\n","Step 280, Loss: 0.11073898524045944\n","Step 290, Loss: 0.11893990635871887\n","Step 300, Loss: 0.13338041305541992\n","Step 310, Loss: 0.11908159404993057\n","Step 320, Loss: 0.1884443163871765\n","Step 330, Loss: 0.12295012176036835\n","Step 340, Loss: 0.09061974287033081\n","Step 350, Loss: 0.11822833865880966\n","Step 360, Loss: 0.18845471739768982\n","Step 370, Loss: 0.11914289742708206\n","Step 380, Loss: 0.17278622090816498\n","Step 390, Loss: 0.12428978085517883\n","Step 400, Loss: 0.09140067547559738\n","Epoch 7 completed with loss 0.09140067547559738\n","Visualizing example 1 of model arc_model_2e-05_7\n","Visualizing example 2 of model arc_model_2e-05_7\n","Visualizing example 3 of model arc_model_2e-05_7\n","Visualizing example 4 of model arc_model_2e-05_7\n","Visualizing example 5 of model arc_model_2e-05_7\n"]},{"output_type":"stream","name":"stderr","text":["/content/arc_benchmark_tutorial/visualize.py:11: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n","  figure, axis = plt.subplots(len(data), 2)\n"]},{"output_type":"stream","name":"stdout","text":["Step 10, Loss: 0.12345870584249496\n","Step 20, Loss: 0.16559936106204987\n","Step 30, Loss: 0.1597554236650467\n","Step 40, Loss: 0.2369728982448578\n","Step 50, Loss: 0.18607106804847717\n","Step 60, Loss: 0.10482193529605865\n","Step 70, Loss: 0.1322905719280243\n","Step 80, Loss: 0.20290160179138184\n","Step 90, Loss: 0.257994145154953\n","Step 100, Loss: 0.10804283618927002\n","Step 110, Loss: 0.27322617173194885\n","Step 120, Loss: 0.20716845989227295\n","Step 130, Loss: 0.1732839047908783\n","Step 140, Loss: 0.22639375925064087\n","Step 150, Loss: 0.2275737226009369\n","Step 160, Loss: 0.1153307557106018\n","Step 170, Loss: 0.30991849303245544\n","Step 180, Loss: 0.09830010682344437\n","Step 190, Loss: 0.18640853464603424\n","Step 200, Loss: 0.25033068656921387\n","Step 210, Loss: 0.3293338418006897\n","Step 220, Loss: 0.23048323392868042\n","Step 230, Loss: 0.1050158217549324\n","Step 240, Loss: 0.37807783484458923\n","Step 250, Loss: 0.0912904143333435\n","Step 260, Loss: 0.04234464839100838\n","Step 270, Loss: 0.4188042879104614\n","Step 280, Loss: 0.13263055682182312\n","Step 290, Loss: 0.30404314398765564\n","Step 300, Loss: 0.2783030569553375\n","Step 310, Loss: 0.13839980959892273\n","Step 320, Loss: 0.1753941923379898\n","Step 330, Loss: 0.18353278934955597\n","Step 340, Loss: 0.09573015570640564\n","Step 350, Loss: 0.15196458995342255\n","Step 360, Loss: 0.12188863009214401\n","Step 370, Loss: 0.23007112741470337\n","Step 380, Loss: 0.38696491718292236\n","Step 390, Loss: 0.25325384736061096\n","Step 400, Loss: 0.18167522549629211\n","Epoch 8 completed with loss 0.18167522549629211\n","Visualizing example 1 of model arc_model_2e-05_8\n","Visualizing example 2 of model arc_model_2e-05_8\n","Visualizing example 3 of model arc_model_2e-05_8\n","Visualizing example 4 of model arc_model_2e-05_8\n","Visualizing example 5 of model arc_model_2e-05_8\n","Step 10, Loss: 0.19178348779678345\n","Step 20, Loss: 0.21520519256591797\n","Step 30, Loss: 0.4436802566051483\n","Step 40, Loss: 0.15572258830070496\n","Step 50, Loss: 0.19685649871826172\n","Step 60, Loss: 0.19767101109027863\n","Step 70, Loss: 1.024800181388855\n","Step 80, Loss: 0.14130662381649017\n","Step 90, Loss: 0.14743924140930176\n","Step 100, Loss: 0.12368007749319077\n","Step 110, Loss: 0.21613988280296326\n","Step 120, Loss: 0.07809987664222717\n","Step 130, Loss: 0.10274802893400192\n","Step 140, Loss: 0.15139752626419067\n","Step 150, Loss: 0.0878545418381691\n","Step 160, Loss: 0.06737132370471954\n","Step 170, Loss: 0.10130716115236282\n","Step 180, Loss: 0.11654573678970337\n","Step 190, Loss: 0.21884740889072418\n","Step 200, Loss: 0.2514863610267639\n","Step 210, Loss: 0.09729860723018646\n","Step 220, Loss: 0.1052352786064148\n","Step 230, Loss: 0.16141948103904724\n","Step 240, Loss: 0.18925423920154572\n","Step 250, Loss: 0.10930409282445908\n","Step 260, Loss: 0.33690157532691956\n","Step 270, Loss: 0.16612263023853302\n","Step 280, Loss: 0.14707119762897491\n","Step 290, Loss: 0.09651444852352142\n","Step 300, Loss: 0.1202060878276825\n","Step 310, Loss: 0.10209815204143524\n","Step 320, Loss: 0.11680231988430023\n","Step 330, Loss: 0.13334248960018158\n","Step 340, Loss: 0.06853985041379929\n","Step 350, Loss: 0.0935247614979744\n","Step 360, Loss: 0.257343590259552\n","Step 370, Loss: 0.1254677027463913\n","Step 380, Loss: 0.3316499590873718\n","Step 390, Loss: 0.13152799010276794\n","Step 400, Loss: 0.1050262302160263\n","Epoch 9 completed with loss 0.1050262302160263\n","Visualizing example 1 of model arc_model_2e-05_9\n","Visualizing example 2 of model arc_model_2e-05_9\n","Visualizing example 3 of model arc_model_2e-05_9\n","Visualizing example 4 of model arc_model_2e-05_9\n","Visualizing example 5 of model arc_model_2e-05_9\n","Step 10, Loss: 0.12701503932476044\n","Step 20, Loss: 0.2074582278728485\n","Step 30, Loss: 0.18610656261444092\n","Step 40, Loss: 0.1250949203968048\n","Step 50, Loss: 0.09594281762838364\n","Step 60, Loss: 0.1301056146621704\n","Step 70, Loss: 0.17222043871879578\n","Step 80, Loss: 0.16703148186206818\n","Step 90, Loss: 0.1275172382593155\n","Step 100, Loss: 0.212389275431633\n","Step 110, Loss: 0.20711080729961395\n","Step 120, Loss: 0.20121783018112183\n","Step 130, Loss: 0.2584134340286255\n","Step 140, Loss: 0.17679566144943237\n","Step 150, Loss: 0.10869523137807846\n","Step 160, Loss: 0.15219813585281372\n","Step 170, Loss: 0.15955370664596558\n","Step 180, Loss: 0.20846553146839142\n","Step 190, Loss: 0.08278533071279526\n","Step 200, Loss: 0.14305318892002106\n","Step 210, Loss: 0.18430155515670776\n","Step 220, Loss: 0.10930155962705612\n","Step 230, Loss: 0.23088842630386353\n","Step 240, Loss: 0.10685818642377853\n","Step 250, Loss: 0.17850765585899353\n","Step 260, Loss: 0.38551729917526245\n","Step 270, Loss: 0.22181962430477142\n","Step 280, Loss: 0.13841697573661804\n","Step 290, Loss: 0.37745940685272217\n","Step 300, Loss: 0.16791851818561554\n","Step 310, Loss: 0.170022115111351\n","Step 320, Loss: 0.15963253378868103\n","Step 330, Loss: 0.18313610553741455\n","Step 340, Loss: 0.15485510230064392\n","Step 350, Loss: 0.16207192838191986\n","Step 360, Loss: 0.19003278017044067\n","Step 370, Loss: 0.10838799923658371\n","Step 380, Loss: 0.11012351512908936\n","Step 390, Loss: 0.34339064359664917\n","Step 400, Loss: 0.14732493460178375\n","Epoch 10 completed with loss 0.14732493460178375\n","Saving model...\n","Model saved\n","Output data has different lengths: [[8, 5, 7, 8, 8, 5, 7, 8], [7, 7, 8, 8, 8, 7, 7, 8], [5, 5, 5, 5, 5, 5, 8, 5, 5], [5, 5, 8, 5, 8, 8, 5, 8, 5], [5, 5, 5, 8, 8, 8, 5, 8, 5], [5, 5, 8, 5, 8, 8, 5, 8, 5], [5, 7, 7, 8, 8, 7, 7, 8, 5], [7, 7, 8, 8, 8, 7, 7, 8, 5], [5, 7, 7, 8, 8, 7, 7, 8, 5]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[8, 5, 7, 8, 8, 5, 7, 8], [7, 7, 8, 8, 8, 7, 7, 8], [5, 5, 5, 5, 5, 5, 8, 5, 5], [5, 5, 8, 5, 8, 8, 5, 8, 5], [5, 5, 5, 8, 8, 8, 5, 8, 5], [5, 5, 8, 5, 8, 8, 5, 8, 5], [5, 7, 7, 8, 8, 7, 7, 8, 5], [7, 7, 8, 8, 8, 7, 7, 8, 5], [5, 7, 7, 8, 8, 7, 7, 8, 5]]\n","Input: [[3, 4, 5, 5], [5, 5, 5, 5], [5, 1, 5, 5]] Output: [[4, 5, 5, 4, 5, 4, 5, 4, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5], [3, 4, 5, 5, 4, 5, 4, 5, 4], [3, 4, 5, 5, 4, 5, 4, 5, 4], [5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5]]\n","Output data has different lengths: [[5, 5, 5, 8, 5, 5, 5, 7, 8, 8], [8, 8, 5, 5, 5, 8, 8, 5, 8, 8], [5, 7, 5, 5, 7, 5, 5, 8, 5, 7, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 8, 5, 8, 5, 5, 5, 5, 5], [5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5], [8, 5, 7, 8, 8, 8, 5, 5, 8, 5, 8], [8, 5, 7, 8, 8, 8, 5, 5, 8, 5, 8], [7, 7, 8, 8, 7, 7, 8, 5, 7, 8, 7], [5, 5, 5, 8, 5, 5, 5, 5, 8, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[5, 5, 5, 8, 5, 5, 5, 7, 8, 8], [8, 8, 5, 5, 5, 8, 8, 5, 8, 8], [5, 7, 5, 5, 7, 5, 5, 8, 5, 7, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 8, 5, 8, 5, 5, 5, 5, 5], [5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5], [8, 5, 7, 8, 8, 8, 5, 5, 8, 5, 8], [8, 5, 7, 8, 8, 8, 5, 5, 8, 5, 8], [7, 7, 8, 8, 7, 7, 8, 5, 7, 8, 7], [5, 5, 5, 8, 5, 5, 5, 5, 8, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]]\n","Visualizing example 3 of model arc_model_2e-05_10\n","Output data has different lengths: [[8, 5, 7, 8, 8, 5, 7, 8], [7, 7, 8, 8, 8, 7, 7, 8], [5, 5, 5, 5, 5, 5, 8, 5, 5], [8, 5, 7, 8, 8, 5, 7, 8, 8], [8, 5, 7, 8, 8, 5, 7, 8, 8], [5, 5, 5, 5, 5, 5, 8, 5, 5], [8, 5, 7, 8, 8, 5, 7, 8, 8], [7, 7, 8, 8, 8, 7, 7, 8, 8], [5, 5, 5, 5, 5, 5, 8, 5, 5]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[8, 5, 7, 8, 8, 5, 7, 8], [7, 7, 8, 8, 8, 7, 7, 8], [5, 5, 5, 5, 5, 5, 8, 5, 5], [8, 5, 7, 8, 8, 5, 7, 8, 8], [8, 5, 7, 8, 8, 5, 7, 8, 8], [5, 5, 5, 5, 5, 5, 8, 5, 5], [8, 5, 7, 8, 8, 5, 7, 8, 8], [7, 7, 8, 8, 8, 7, 7, 8, 8], [5, 5, 5, 5, 5, 5, 8, 5, 5]]\n","Visualizing example 5 of model arc_model_2e-05_10\n","Step 10, Loss: 0.16251838207244873\n","Step 20, Loss: 0.17869442701339722\n","Step 30, Loss: 0.21036167442798615\n","Step 40, Loss: 0.24745899438858032\n","Step 50, Loss: 0.10470101237297058\n","Step 60, Loss: 0.13701628148555756\n","Step 70, Loss: 0.13280253112316132\n","Step 80, Loss: 0.11541157215833664\n","Step 90, Loss: 0.17475809156894684\n","Step 100, Loss: 0.12166690081357956\n","Step 110, Loss: 0.07584670186042786\n","Step 120, Loss: 0.3878663182258606\n","Step 130, Loss: 0.04946737736463547\n","Step 140, Loss: 0.1515582650899887\n","Step 150, Loss: 0.31710144877433777\n","Step 160, Loss: 0.1701551079750061\n","Step 170, Loss: 0.11522611975669861\n","Step 180, Loss: 0.1414448469877243\n","Step 190, Loss: 0.1809636950492859\n","Step 200, Loss: 0.2414979338645935\n","Step 210, Loss: 0.07346170395612717\n","Step 220, Loss: 0.19552814960479736\n","Step 230, Loss: 0.1855304092168808\n","Step 240, Loss: 0.12873753905296326\n","Step 250, Loss: 0.1353868544101715\n","Step 260, Loss: 0.172554612159729\n","Step 270, Loss: 0.09136461466550827\n","Step 280, Loss: 0.14163126051425934\n","Step 290, Loss: 0.14492648839950562\n","Step 300, Loss: 0.1283324956893921\n","Step 310, Loss: 0.15186889469623566\n","Step 320, Loss: 0.16821438074111938\n","Step 330, Loss: 0.8389173746109009\n","Step 340, Loss: 0.06472132354974747\n","Step 350, Loss: 0.2578897476196289\n","Step 360, Loss: 0.19645676016807556\n","Step 370, Loss: 0.08206959813833237\n","Step 380, Loss: 0.24179242551326752\n","Step 390, Loss: 0.18450842797756195\n","Step 400, Loss: 0.12695744633674622\n","Epoch 11 completed with loss 0.12695744633674622\n","Visualizing example 1 of model arc_model_2e-05_11\n","Visualizing example 2 of model arc_model_2e-05_11\n","Visualizing example 3 of model arc_model_2e-05_11\n","Visualizing example 4 of model arc_model_2e-05_11\n","Visualizing example 5 of model arc_model_2e-05_11\n","Step 10, Loss: 0.13766944408416748\n","Step 20, Loss: 0.09820205718278885\n","Step 30, Loss: 0.09617314487695694\n","Step 40, Loss: 0.16476517915725708\n","Step 50, Loss: 0.1585269719362259\n","Step 60, Loss: 0.1150459498167038\n","Step 70, Loss: 0.3014075756072998\n","Step 80, Loss: 0.0926237478852272\n","Step 90, Loss: 0.1349875032901764\n","Step 100, Loss: 0.047060973942279816\n","Step 110, Loss: 0.12354112416505814\n","Step 120, Loss: 0.2269311398267746\n","Step 130, Loss: 0.08492646366357803\n","Step 140, Loss: 0.12715592980384827\n","Step 150, Loss: 0.19399090111255646\n","Step 160, Loss: 0.3175734877586365\n","Step 170, Loss: 0.1389121413230896\n","Step 180, Loss: 0.14076413214206696\n","Step 190, Loss: 0.2202480584383011\n","Step 200, Loss: 0.24006503820419312\n","Step 210, Loss: 0.0894426628947258\n","Step 220, Loss: 0.08771292120218277\n","Step 230, Loss: 0.6467896103858948\n","Step 240, Loss: 0.3401106894016266\n","Step 250, Loss: 0.14022940397262573\n","Step 260, Loss: 0.20715245604515076\n","Step 270, Loss: 0.08746550977230072\n","Step 280, Loss: 0.14302901923656464\n","Step 290, Loss: 0.1725422590970993\n","Step 300, Loss: 0.1001579612493515\n","Step 310, Loss: 0.08138944953680038\n","Step 320, Loss: 0.31556519865989685\n","Step 330, Loss: 0.1673051118850708\n","Step 340, Loss: 0.20649100840091705\n","Step 350, Loss: 0.11175525933504105\n","Step 360, Loss: 0.13738612830638885\n","Step 370, Loss: 0.09883090108633041\n","Step 380, Loss: 0.1743793785572052\n","Step 390, Loss: 0.10879099369049072\n","Step 400, Loss: 0.194855198264122\n","Epoch 12 completed with loss 0.194855198264122\n","Visualizing example 1 of model arc_model_2e-05_12\n","Visualizing example 2 of model arc_model_2e-05_12\n","Visualizing example 3 of model arc_model_2e-05_12\n","Visualizing example 4 of model arc_model_2e-05_12\n","Visualizing example 5 of model arc_model_2e-05_12\n","Step 10, Loss: 0.11129103600978851\n","Step 20, Loss: 0.12034192681312561\n","Step 30, Loss: 0.09561801701784134\n","Step 40, Loss: 0.09414441883563995\n","Step 50, Loss: 0.11704626679420471\n","Step 60, Loss: 0.1751643270254135\n","Step 70, Loss: 0.17961695790290833\n","Step 80, Loss: 0.12222041934728622\n","Step 90, Loss: 0.05597684532403946\n","Step 100, Loss: 0.1621682345867157\n","Step 110, Loss: 0.17639586329460144\n","Step 120, Loss: 0.1523551344871521\n","Step 130, Loss: 0.07792990654706955\n","Step 140, Loss: 0.04235758259892464\n","Step 150, Loss: 0.16676442325115204\n","Step 160, Loss: 0.1901613026857376\n","Step 170, Loss: 0.4901200830936432\n","Step 180, Loss: 0.1292220503091812\n","Step 190, Loss: 0.21169891953468323\n","Step 200, Loss: 0.08558493852615356\n","Step 210, Loss: 0.19067536294460297\n","Step 220, Loss: 0.1036859005689621\n","Step 230, Loss: 0.07571174949407578\n","Step 240, Loss: 0.08046244829893112\n","Step 250, Loss: 0.11156705766916275\n","Step 260, Loss: 0.08537152409553528\n","Step 270, Loss: 0.17613233625888824\n","Step 280, Loss: 0.12408152967691422\n","Step 290, Loss: 0.1405455470085144\n","Step 300, Loss: 0.07502520084381104\n","Step 310, Loss: 0.1146269291639328\n","Step 320, Loss: 0.13176903128623962\n","Step 330, Loss: 0.06577640771865845\n","Step 340, Loss: 0.10259934514760971\n","Step 350, Loss: 0.09324834495782852\n","Step 360, Loss: 0.07502220571041107\n","Step 370, Loss: 0.6184321045875549\n","Step 380, Loss: 0.2739923596382141\n","Step 390, Loss: 0.1671273410320282\n","Step 400, Loss: 0.4259321987628937\n","Epoch 13 completed with loss 0.4259321987628937\n","Visualizing example 1 of model arc_model_2e-05_13\n","Visualizing example 2 of model arc_model_2e-05_13\n","Visualizing example 3 of model arc_model_2e-05_13\n","Visualizing example 4 of model arc_model_2e-05_13\n","Output data has different lengths: [[8, 5, 7, 8, 8, 5, 7, 8], [7, 7, 8, 8, 7, 7, 7, 8], [5, 5, 8, 5, 5, 8, 5, 8], [8, 5, 7, 8, 8, 8, 5, 7, 8], [7, 7, 8, 8, 7, 7, 7, 8], [5, 5, 8, 5, 5, 8, 5, 8], [8, 5, 7, 8, 8, 8, 5, 7, 8]]: Input: [[6, 2, 4, 2], [2, 2, 6, 6], [6, 4, 2, 4]] Output: [[4, 2, 4, 6, 6, 4, 2, 4], [6, 6, 2, 2, 2, 2, 6, 6], [2, 4, 2, 6, 6, 2, 4, 2], [2, 4, 2, 6, 6, 2, 4, 2], [6, 6, 2, 2, 2, 2, 6, 6], [4, 2, 4, 6, 6, 4, 2, 4]]\n","Input: [[5, 5, 9, 9], [9, 5, 5, 5], [5, 7, 5, 7]] Output: [[7, 5, 7, 5, 5, 7, 5, 7], [5, 5, 5, 9, 9, 5, 5, 5], [9, 9, 5, 5, 5, 5, 9, 9], [9, 9, 5, 5, 5, 5, 9, 9], [5, 5, 5, 9, 9, 5, 5, 5], [7, 5, 7, 5, 5, 7, 5, 7]]\n","Input: [[3, 3, 5, 5], [5, 8, 5, 8], [8, 8, 5, 8]] Output: [[8, 5, 8, 8, 8, 8, 5, 8], [8, 5, 8, 5, 5, 8, 5, 8], [5, 5, 3, 3, 3, 3, 5, 5], [5, 5, 3, 3, 3, 3, 5, 5], [8, 5, 8, 5, 5, 8, 5, 8], [8, 5, 8, 8, 8, 8, 5, 8]]\n","Input: [[8, 5, 7, 8], [7, 7, 8, 8], [5, 5, 8, 5]] Output: [[8, 5, 7, 8, 8, 5, 7, 8], [7, 7, 8, 8, 7, 7, 7, 8], [5, 5, 8, 5, 5, 8, 5, 8], [8, 5, 7, 8, 8, 8, 5, 7, 8], [7, 7, 8, 8, 7, 7, 7, 8], [5, 5, 8, 5, 5, 8, 5, 8], [8, 5, 7, 8, 8, 8, 5, 7, 8]]\n","Step 10, Loss: 0.09169819951057434\n","Step 20, Loss: 0.16404131054878235\n","Step 30, Loss: 0.09748972207307816\n","Step 40, Loss: 0.11401937156915665\n","Step 50, Loss: 0.26994451880455017\n","Step 60, Loss: 0.19341202080249786\n","Step 70, Loss: 0.09388688206672668\n","Step 80, Loss: 0.09860973060131073\n","Step 90, Loss: 0.07394189387559891\n","Step 100, Loss: 0.08720739930868149\n","Step 110, Loss: 0.13263918459415436\n","Step 120, Loss: 0.13922838866710663\n","Step 130, Loss: 0.19919151067733765\n","Step 140, Loss: 0.10824187099933624\n","Step 150, Loss: 0.13211917877197266\n","Step 160, Loss: 0.0695086419582367\n","Step 170, Loss: 0.16426147520542145\n","Step 180, Loss: 0.25731074810028076\n","Step 190, Loss: 0.09138823300600052\n","Step 200, Loss: 0.14793726801872253\n","Step 210, Loss: 0.08743786066770554\n","Step 220, Loss: 0.05287637561559677\n","Step 230, Loss: 0.11601772904396057\n","Step 240, Loss: 0.0782584547996521\n","Step 250, Loss: 0.15253311395645142\n","Step 260, Loss: 0.10804608464241028\n","Step 270, Loss: 0.23958775401115417\n","Step 280, Loss: 0.17734484374523163\n","Step 290, Loss: 0.10188059508800507\n","Step 300, Loss: 0.16611860692501068\n","Step 310, Loss: 0.10141738504171371\n","Step 320, Loss: 0.4555642604827881\n","Step 330, Loss: 0.05406516045331955\n","Step 340, Loss: 0.09730161726474762\n","Step 350, Loss: 0.13464230298995972\n","Step 360, Loss: 0.09047769755125046\n","Step 370, Loss: 0.25557947158813477\n","Step 380, Loss: 0.07234632968902588\n","Step 390, Loss: 0.10050684213638306\n","Step 400, Loss: 0.07077436149120331\n","Epoch 14 completed with loss 0.07077436149120331\n","Visualizing example 1 of model arc_model_2e-05_14\n","Visualizing example 2 of model arc_model_2e-05_14\n","Visualizing example 3 of model arc_model_2e-05_14\n","Visualizing example 4 of model arc_model_2e-05_14\n","Visualizing example 5 of model arc_model_2e-05_14\n","Step 10, Loss: 0.1551513522863388\n","Step 20, Loss: 0.10750867426395416\n","Step 30, Loss: 0.1712888926267624\n","Step 40, Loss: 0.07706502825021744\n","Step 50, Loss: 0.08357562124729156\n","Step 60, Loss: 0.05490819364786148\n","Step 70, Loss: 0.19010411202907562\n","Step 80, Loss: 0.22557809948921204\n","Step 90, Loss: 0.17714102566242218\n","Step 100, Loss: 0.12277419865131378\n","Step 110, Loss: 0.22539402544498444\n","Step 120, Loss: 0.19636863470077515\n","Step 130, Loss: 0.11348097026348114\n","Step 140, Loss: 0.11382424086332321\n","Step 150, Loss: 0.2292715460062027\n","Step 160, Loss: 0.18551947176456451\n","Step 170, Loss: 0.10181283205747604\n","Step 180, Loss: 0.325057715177536\n","Step 190, Loss: 0.13040588796138763\n","Step 200, Loss: 0.2905055582523346\n","Step 210, Loss: 0.12618893384933472\n","Step 220, Loss: 0.17486098408699036\n","Step 230, Loss: 0.13577933609485626\n","Step 240, Loss: 0.22914066910743713\n","Step 250, Loss: 0.06825917959213257\n","Step 260, Loss: 0.14222151041030884\n","Step 270, Loss: 0.07618098706007004\n","Step 280, Loss: 0.1339208036661148\n","Step 290, Loss: 0.12711775302886963\n","Step 300, Loss: 0.0688444972038269\n","Step 310, Loss: 0.08792632073163986\n","Step 320, Loss: 0.29974788427352905\n","Step 330, Loss: 0.07605773210525513\n","Step 340, Loss: 0.10661080479621887\n","Step 350, Loss: 0.06889611482620239\n","Step 360, Loss: 0.21833491325378418\n","Step 370, Loss: 0.08736314624547958\n","Step 380, Loss: 0.1272863894701004\n","Step 390, Loss: 0.08410010486841202\n","Step 400, Loss: 0.167143777012825\n","Epoch 15 completed with loss 0.167143777012825\n","Visualizing example 1 of model arc_model_2e-05_15\n","Visualizing example 2 of model arc_model_2e-05_15\n","Visualizing example 3 of model arc_model_2e-05_15\n","Visualizing example 4 of model arc_model_2e-05_15\n","Visualizing example 5 of model arc_model_2e-05_15\n","Step 10, Loss: 0.08039514720439911\n","Step 20, Loss: 0.1120578870177269\n","Step 30, Loss: 0.269025593996048\n","Step 40, Loss: 0.11893367767333984\n","Step 50, Loss: 0.05790334939956665\n","Step 60, Loss: 0.3553004860877991\n","Step 70, Loss: 0.09060751646757126\n","Step 80, Loss: 0.08220773935317993\n","Step 90, Loss: 0.2972334921360016\n","Step 100, Loss: 0.06848705559968948\n","Step 110, Loss: 0.14895015954971313\n","Step 120, Loss: 0.17524713277816772\n","Step 130, Loss: 0.0907205268740654\n","Step 140, Loss: 0.11097349226474762\n","Step 150, Loss: 0.07652867585420609\n","Step 160, Loss: 0.11508823186159134\n","Step 170, Loss: 0.25575366616249084\n","Step 180, Loss: 0.4418478012084961\n","Step 190, Loss: 0.12196432054042816\n","Step 200, Loss: 0.042895469814538956\n","Step 210, Loss: 0.1414756178855896\n","Step 220, Loss: 0.12358829379081726\n","Step 230, Loss: 0.15523524582386017\n","Step 240, Loss: 0.06707055866718292\n","Step 250, Loss: 0.2886293828487396\n","Step 260, Loss: 0.045400917530059814\n","Step 270, Loss: 0.1567031592130661\n","Step 280, Loss: 0.11711382120847702\n","Step 290, Loss: 0.12546612322330475\n","Step 300, Loss: 0.18397341668605804\n","Step 310, Loss: 0.08221065998077393\n","Step 320, Loss: 0.10355576127767563\n","Step 330, Loss: 0.1523813009262085\n","Step 340, Loss: 0.1964077204465866\n","Step 350, Loss: 0.1917961984872818\n","Step 360, Loss: 0.10772374272346497\n","Step 370, Loss: 0.1435360461473465\n","Step 380, Loss: 0.1430426388978958\n","Step 390, Loss: 0.1102503091096878\n","Step 400, Loss: 0.13460567593574524\n","Epoch 16 completed with loss 0.13460567593574524\n","Visualizing example 1 of model arc_model_2e-05_16\n","Visualizing example 2 of model arc_model_2e-05_16\n","Visualizing example 3 of model arc_model_2e-05_16\n","Visualizing example 4 of model arc_model_2e-05_16\n","Visualizing example 5 of model arc_model_2e-05_16\n","Step 10, Loss: 0.2030857354402542\n","Step 20, Loss: 0.15580087900161743\n","Step 30, Loss: 0.11921776086091995\n","Step 40, Loss: 0.2765488922595978\n","Step 50, Loss: 0.3006712794303894\n","Step 60, Loss: 0.10927533358335495\n","Step 70, Loss: 0.11324267089366913\n","Step 80, Loss: 0.0892069861292839\n","Step 90, Loss: 0.14748722314834595\n","Step 100, Loss: 0.19305534660816193\n","Step 110, Loss: 0.09511256963014603\n","Step 120, Loss: 0.11919840425252914\n","Step 130, Loss: 0.08628711849451065\n","Step 140, Loss: 0.2681899070739746\n","Step 150, Loss: 0.36954453587532043\n","Step 160, Loss: 0.15184400975704193\n","Step 170, Loss: 0.07348550856113434\n","Step 180, Loss: 0.0765242800116539\n","Step 190, Loss: 0.05576615780591965\n","Step 200, Loss: 0.27433037757873535\n","Step 210, Loss: 0.11511094123125076\n","Step 220, Loss: 0.30232056975364685\n","Step 230, Loss: 0.15992224216461182\n","Step 240, Loss: 0.10372769087553024\n","Step 250, Loss: 0.07532789558172226\n","Step 260, Loss: 0.15407556295394897\n","Step 270, Loss: 0.0903879851102829\n","Step 280, Loss: 0.147511824965477\n","Step 290, Loss: 0.14962832629680634\n","Step 300, Loss: 0.09177997708320618\n","Step 310, Loss: 0.09235872328281403\n","Step 320, Loss: 0.10837416350841522\n","Step 330, Loss: 0.16349457204341888\n","Step 340, Loss: 0.054954126477241516\n","Step 350, Loss: 0.24620836973190308\n","Step 360, Loss: 0.1298510581254959\n","Step 370, Loss: 0.10916095227003098\n","Step 380, Loss: 0.09314742684364319\n","Step 390, Loss: 0.1415107697248459\n","Step 400, Loss: 0.15308792889118195\n","Epoch 17 completed with loss 0.15308792889118195\n","Visualizing example 1 of model arc_model_2e-05_17\n","Visualizing example 2 of model arc_model_2e-05_17\n","Visualizing example 3 of model arc_model_2e-05_17\n","Visualizing example 4 of model arc_model_2e-05_17\n","Visualizing example 5 of model arc_model_2e-05_17\n","Step 10, Loss: 0.07942086458206177\n","Step 20, Loss: 0.29983922839164734\n","Step 30, Loss: 0.14867404103279114\n","Step 40, Loss: 0.17569909989833832\n","Step 50, Loss: 0.05485224723815918\n","Step 60, Loss: 0.23760190606117249\n","Step 70, Loss: 0.17856213450431824\n","Step 80, Loss: 0.07453865557909012\n","Step 90, Loss: 0.24179720878601074\n","Step 100, Loss: 0.13156042993068695\n","Step 110, Loss: 0.09796976298093796\n","Step 120, Loss: 0.08290082961320877\n","Step 130, Loss: 0.13181838393211365\n","Step 140, Loss: 0.2155829519033432\n","Step 150, Loss: 0.414602130651474\n","Step 160, Loss: 0.12636783719062805\n","Step 170, Loss: 0.10215717554092407\n","Step 180, Loss: 0.05723947659134865\n","Step 190, Loss: 0.06470843404531479\n","Step 200, Loss: 0.09590915590524673\n","Step 210, Loss: 0.1079321801662445\n","Step 220, Loss: 0.19647999107837677\n","Step 230, Loss: 0.0951201468706131\n","Step 240, Loss: 0.34196025133132935\n","Step 250, Loss: 0.06934519857168198\n","Step 260, Loss: 0.10046372562646866\n","Step 270, Loss: 0.09877672791481018\n","Step 280, Loss: 0.10680791735649109\n","Step 290, Loss: 0.1020125076174736\n","Step 300, Loss: 0.1115051805973053\n","Step 310, Loss: 0.17470206320285797\n","Step 320, Loss: 0.10978130996227264\n","Step 330, Loss: 0.10862163454294205\n","Step 340, Loss: 0.07780018448829651\n","Step 350, Loss: 0.07325882464647293\n","Step 360, Loss: 0.11124297976493835\n","Step 370, Loss: 0.14510615170001984\n","Step 380, Loss: 0.10583028942346573\n","Step 390, Loss: 0.06654885411262512\n","Step 400, Loss: 0.10171019285917282\n","Epoch 18 completed with loss 0.10171019285917282\n","Visualizing example 1 of model arc_model_2e-05_18\n","Visualizing example 2 of model arc_model_2e-05_18\n","Visualizing example 3 of model arc_model_2e-05_18\n","Visualizing example 4 of model arc_model_2e-05_18\n","Visualizing example 5 of model arc_model_2e-05_18\n","Step 10, Loss: 0.059433504939079285\n","Step 20, Loss: 0.16579490900039673\n","Step 30, Loss: 0.13601677119731903\n","Step 40, Loss: 0.1084427759051323\n","Step 50, Loss: 0.13653428852558136\n","Step 60, Loss: 0.11490964144468307\n","Step 70, Loss: 0.08433543890714645\n","Step 80, Loss: 0.13110864162445068\n","Step 90, Loss: 0.0852242037653923\n","Step 100, Loss: 0.15296097099781036\n","Step 110, Loss: 0.08080074936151505\n","Step 120, Loss: 0.13280682265758514\n","Step 130, Loss: 0.13567236065864563\n","Step 140, Loss: 0.08712679892778397\n","Step 150, Loss: 0.0938681960105896\n","Step 160, Loss: 0.08248945325613022\n","Step 170, Loss: 0.13135406374931335\n","Step 180, Loss: 0.05982618033885956\n","Step 190, Loss: 0.06979279965162277\n","Step 200, Loss: 0.11905570328235626\n","Step 210, Loss: 0.06795749813318253\n","Step 220, Loss: 0.08869822323322296\n","Step 230, Loss: 0.14148646593093872\n","Step 240, Loss: 0.15982379019260406\n","Step 250, Loss: 0.10073664784431458\n","Step 260, Loss: 0.09874153137207031\n","Step 270, Loss: 0.1820313036441803\n"]}]}]}